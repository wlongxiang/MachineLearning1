{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Save this file as studentid1_studentid2_lab#.ipynb**\n",
    "(Your student-id is the number shown on your student card.)\n",
    "\n",
    "E.g. if you work with 3 people, the notebook should be named:\n",
    "12301230_3434343_1238938934_lab1.ipynb.\n",
    "\n",
    "**This will be parsed by a regexp, so please double check your filename.**\n",
    "\n",
    "**Only one member of each group has to submit the file to canvas.**\n",
    "\n",
    "Before you turn this problem in, please make sure everything runs correctly. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). Note, that **you are not allowed to use Google Colab**.\n",
    "\n",
    "**Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your names and email adresses below.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Longxiang Wang\"\n",
    "NAME2 = \"Ruihan Sun\"\n",
    "NAME3 = \"\"\n",
    "EMAIL = \"wlongxiang1119@gmail.com\"\n",
    "EMAIL2 = \"sunx0495@umn.edu\"\n",
    "EMAIL3 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b22ed1acdb2741724545bc4572dfdd1",
     "grade": false,
     "grade_id": "cell-447a8ab4c82429ab",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Lab 1: Linear Regression and Overfitting\n",
    "\n",
    "### Machine Learning 1, September/October 2019\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in this IPython Notebook: http://ipython.org/notebook.html. If you have problems, please contact your teaching assistant.\n",
    "* Please write your answers right below the questions.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
    "* Refer to last week's lab notes, i.e. http://docs.scipy.org/doc/, if you are unsure about what function to use. There are different correct ways to implement each problem!\n",
    "* For this lab, your regression solutions should be in closed form, i.e., should not perform iterative gradient-based optimization but find the exact optimum directly.\n",
    "* use the provided test boxes to check if your answers are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9c278ee9abc89a5ef5d829c1049141d2",
     "grade": false,
     "grade_id": "cell-a31fbe1e5a0de9bb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.rcParams[\"figure.figsize\"] = [20,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b8f7cda7af52c167af0093d9957406f3",
     "grade": false,
     "grade_id": "cell-369c3e293a3f9c73",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell makes sure that you have all the necessary libraries installed\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "from importlib.util import find_spec, module_from_spec\n",
    "\n",
    "def check_newer_version(version_inst, version_nec):\n",
    "    version_inst_split = version_inst.split('.')\n",
    "    version_nec_split = version_nec.split('.')\n",
    "    for i in range(min(len(version_inst_split), len(version_nec_split))):\n",
    "        if int(version_nec_split[i]) > int(version_inst_split[i]):\n",
    "            return False\n",
    "        elif int(version_nec_split[i]) < int(version_inst_split[i]):\n",
    "            return True\n",
    "    return True\n",
    "\n",
    "\n",
    "module_list = [('jupyter', '1.0.0'), \n",
    "               ('matplotlib', '2.0.2'), \n",
    "               ('numpy', '1.13.1'), \n",
    "               ('python', '3.6.2'), \n",
    "               ('sklearn', '0.19.0'), \n",
    "               ('scipy', '0.19.1'), \n",
    "               ('nb_conda', '2.2.1')]\n",
    "\n",
    "packages_correct = True\n",
    "packages_errors = []\n",
    "\n",
    "for module_name, version in module_list:\n",
    "    if module_name == 'scikit-learn':\n",
    "        module_name = 'sklearn'\n",
    "    if 'python' in module_name:\n",
    "        python_version = platform.python_version()\n",
    "        if not check_newer_version(python_version, version):\n",
    "            packages_correct = False\n",
    "            error = f'Update {module_name} to version {version}. Current version is {python_version}.'\n",
    "            packages_errors.append(error) \n",
    "            print(error)\n",
    "    else:\n",
    "        spec = find_spec(module_name)\n",
    "        if spec is None:\n",
    "            packages_correct = False\n",
    "            error = f'Install {module_name} with version {version} or newer, it is required for this assignment!'\n",
    "            packages_errors.append(error) \n",
    "            print(error)\n",
    "        else:\n",
    "            x = __import__(module_name)\n",
    "            if hasattr(x, '__version__') and not check_newer_version(x.__version__, version):\n",
    "                packages_correct = False\n",
    "                error = f'Update {module_name} to version {version}. Current version is {x.__version__}.'\n",
    "                packages_errors.append(error) \n",
    "                print(error)\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    packages_correct = False\n",
    "    error = \"\"\"Please, don't use google colab!\n",
    "It will make it much more complicated for us to check your homework as it merges all the cells into one.\"\"\"\n",
    "    packages_errors.append(error) \n",
    "    print(error)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "packages_errors = '\\n'.join(packages_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da272b2022410b91aa71d1666edbc7d0",
     "grade": false,
     "grade_id": "cell-b10d09d2f9867804",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "$\\newcommand{\\bPhi}{\\mathbf{\\Phi}}$\n",
    "$\\newcommand{\\bx}{\\mathbf{x}}$\n",
    "$\\newcommand{\\bw}{\\mathbf{w}}$\n",
    "$\\newcommand{\\bt}{\\mathbf{t}}$\n",
    "$\\newcommand{\\by}{\\mathbf{y}}$\n",
    "$\\newcommand{\\bm}{\\mathbf{m}}$\n",
    "$\\newcommand{\\bS}{\\mathbf{S}}$\n",
    "$\\newcommand{\\bI}{\\mathbf{I}}$\n",
    "\n",
    "## Part 1: Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8eb078099e4f5ea7c53df3841d5bfeb3",
     "grade": false,
     "grade_id": "cell-505d034435d52b27",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1. Generate periodic data (5 points)\n",
    "Write a method `gen_sine(N)` that generates toy data like in fig 1.2 of Bishop's book. The method should have a parameter $N$, and should return $N$-dimensional vectors $\\bx$ and $\\bt$, where $\\bx$ contains evenly spaced values from 0 to (including) 2$\\pi$, and the elements $t_i$ of $\\bt$ are distributed according to:\n",
    "\n",
    "$$t_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2)$$\n",
    "\n",
    "where $x_i$ is the $i$-th elements of $\\bf{x}$, the mean $\\mu_i = \\sin(x_i)$ and the standard deviation $\\sigma = 0.25$. You can make use of `np.random.normal()` (Hint: Double check its input parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "49937550875b0f9110c39ecfeca2e48e",
     "grade": false,
     "grade_id": "cell-1c8c68d862f80f7e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gen_sine(n):\n",
    "    # YOUR CODE HERE\n",
    "    x = np.linspace(0, 2*np.pi, n, endpoint = True)\n",
    "    u = np.sin(x)\n",
    "    t = np.random.normal(u, 0.25, n)\n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "06c7e4b785bfefb251544e053366c004",
     "grade": true,
     "grade_id": "cell-afc3c8025a62af85",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "np.random.seed(42)\n",
    "N = 10\n",
    "x, t = gen_sine(N)\n",
    "\n",
    "assert x.shape == (N,), \"the shape of x is incorrect\"\n",
    "assert t.shape == (N,), \"the shape of t is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Visualize the plot\n",
    "x, t = gen_sine(40)\n",
    "plt.scatter(x, t, label=\"samples\")\n",
    "plt.plot(x, np.sin(x),'g', label=\"sin(x)\")\n",
    "plt.title('Viz')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"t\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "36f1c468a11a98927757083b3f43db4d",
     "grade": false,
     "grade_id": "cell-22a999e8760129f8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Polynomial regression (10 points)\n",
    "\n",
    "Write a method `fit_polynomial(x, t, M)` that finds the maximum-likelihood solution of an _unregularized_ $M$-th order polynomial for some dataset `x`. The error function to minimize w.r.t. $\\bw$ is:\n",
    "\n",
    "$E(\\bw) = \\frac{1}{2} (\\bPhi\\bw - \\bt)^T(\\bPhi\\bw - \\bt)$\n",
    "\n",
    "where $\\bPhi$ is the _feature matrix_ (or _design matrix_) as explained in Bishop's book at section 3.1.1, $\\bt$ is the vector of target values. Your method should return a vector $\\bw$ with the maximum-likelihood parameter estimates, as well as the _feature matrix_ $\\bPhi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e5f21a1de6f35ff5c520db69540d71c7",
     "grade": false,
     "grade_id": "cell-27b0d6f1bcdeb97b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def designmatrix(x, M): # it is highly recommended to write a helper function that computes Phi\n",
    "    # YOUR CODE HERE\n",
    "    matrix = np.ones((x.shape[0],M+1))\n",
    "    for i in range(1,M+1) :\n",
    "        matrix[:,i] = x**i\n",
    "    return matrix\n",
    "\n",
    "def fit_polynomial(x, t, M):\n",
    "    # YOUR CODE HERE\n",
    "    Phi = designmatrix(x,M)\n",
    "    # w_ml = np.linalg.inv(Phi.T @ Phi) @ Phi.T @ t\n",
    "    # somehow the pinv works well than the manual method above for M=12 especially\n",
    "    w_ml = np.linalg.pinv(Phi).dot(t)\n",
    "    return w_ml, Phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(x, t, M):\n",
    "    Phi =designmatrix(x, M)\n",
    "    # here we use numpy builtin to calculate the peudo inverse\n",
    "    return w_ml, Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed92cddb718e1dd55d7a0d1cc1d623a7",
     "grade": true,
     "grade_id": "cell-7e0f87e75d7c82aa",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w_ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a7f412e3c410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_polynomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"The shape of w is incorrect\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cad633358c28>\u001b[0m in \u001b[0;36mfit_polynomial\u001b[0;34m(x, t, M)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mPhi\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdesignmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# here we use numpy builtin to calculate the peudo inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mw_ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'w_ml' is not defined"
     ]
    }
   ],
   "source": [
    "### Test your function\n",
    "N = 10\n",
    "x = np.linspace(-1, 1, N)\n",
    "t = 0.3*np.square(x) + 2.5\n",
    "m = 2\n",
    "w, Phi = fit_polynomial(x,t,m)\n",
    "\n",
    "assert w.shape == (m+1,), \"The shape of w is incorrect\"\n",
    "assert Phi.shape == (N, m+1), \"The shape of Phi is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "36a4843effb733479987c3d11dba190f",
     "grade": false,
     "grade_id": "cell-f4d51f8338ebdb54",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3 Plot (5 points)\n",
    "Sample a dataset with $N=10$, and fit four polynomials with $M \\in (0, 2, 4, 8)$.\n",
    "For each value of $M$, plot the prediction function, along with the data and the original sine function. The resulting figure should look similar to fig 1.4 of the Bishop's book. Note that you can use matplotlib's `plt.pyplot(.)` functionality for creating grids of figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dataset\n",
    "x, t = gen_sine(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0009313fff1f2cd716d4e81f0f2ec5ff",
     "grade": true,
     "grade_id": "cell-2774a098ae80cb7e",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M = [0,2,4,8]\n",
    "N = 10\n",
    "plt.rcParams[\"figure.figsize\"] = [20,10]\n",
    "for i in range(len(M)):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.plot(x, t, 'ro')\n",
    "    w, Phi = fit_polynomial(x,t,M[i])\n",
    "\n",
    "    pred_x = np.linspace(0, 2*np.pi, 100)\n",
    "    detailed_Phi = designmatrix(pred_x, M[i])\n",
    "    pred = detailed_Phi.dot(w)\n",
    "    plt.plot(pred_x,np.sin(pred_x), linewidth=2.5)\n",
    "    plt.plot(pred_x, pred,'g')\n",
    "    plt.legend([\"samples\",\"sin(x)\", \"polynomial fit\"])\n",
    "    plt.title(\"Order M={}\".format(M[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8cfb34f3c48cb57d65c4e054c3dd7418",
     "grade": false,
     "grade_id": "cell-2597ee45cb3998ed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.4 Regularized linear regression (15 points)\n",
    "\n",
    "a) (10 points) Write a method `fit_polynomial_reg(x, t, M, lamb)` that fits a _regularized_ $M$-th order polynomial to the periodic data, as discussed in the lectures, where `lamb` is the regularization term _lambda_. (Note that 'lambda' cannot be used as a variable name in Python since it has a special meaning). The error function to minimize w.r.t. $\\bw$:\n",
    "\n",
    "$E(\\bw) = \\frac{1}{2} (\\bPhi\\bw - \\bt)^T(\\bPhi\\bw - \\bt) + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w}$\n",
    "\n",
    "For background, see section 3.1.4 of Bishop's book.\n",
    "\n",
    "The function should return $\\bw$ and $\\bPhi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dc76736fba956e5d9cc51a318c2507c3",
     "grade": false,
     "grade_id": "cell-9fe81fd5537daff9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_polynomial_reg(x, t, m, lamb):\n",
    "    # YOUR CODE HERE\n",
    "    Phi = designmatrix(x,m)\n",
    "    w_ml = np.linalg.inv(lamb * np.identity(m+1) + Phi.T @ Phi) @ Phi.T @ t\n",
    "    return w_ml, Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "385d6b45a599e72289ac08f2c948303d",
     "grade": true,
     "grade_id": "cell-a2e561cbc5a4140b",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "N = 10\n",
    "x = np.linspace(-1, 1, N)\n",
    "t = 0.3*np.square(x) + 2.5\n",
    "m = 2\n",
    "lamb = 0.1\n",
    "w, Phi = fit_polynomial_reg(x,t,m, lamb)\n",
    "\n",
    "assert w.shape == (m+1,), \"The shape of w is incorrect\"\n",
    "assert Phi.shape == (N, m+1), \"The shape of w is incorrect\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [0,2,4,6,8,10,12,14]\n",
    "N = 10\n",
    "for i in range(len(M)):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    x, t = gen_sine(N)\n",
    "    plt.plot(x, t, 'ro')\n",
    "    w, Phi = fit_polynomial(x,t,M[i])\n",
    "    w_reg, Phi_reg = fit_polynomial_reg(x,t,M[i], 0.1)\n",
    "\n",
    "    pred_x = np.linspace(0, 2*np.pi, 100)\n",
    "    detailed_Phi = designmatrix(pred_x, M[i])\n",
    "    pred = detailed_Phi.dot(w)\n",
    "    pred_reg = detailed_Phi.dot(w_reg)\n",
    "    plt.plot(pred_x, pred, \"g\", label=\"unreg\")\n",
    "    plt.plot(pred_x, pred_reg, \"b\", label=\"reg\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"M={}\".format(M[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fc475bda964b3b8bccbddc9882867984",
     "grade": false,
     "grade_id": "cell-ef31ad7f9dde2832",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "b) (5 points) What changes do you notice in $\\bw$ and $\\bPhi$ after introducing the regularization term? Why is this happening? \n",
    "\n",
    "(Write no more than 5 lines. For example, you can consider the simple test case with $t = 0.3*x^2 + 2.5$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8990249d9a7d7ab5efc9132556eedc79",
     "grade": true,
     "grade_id": "cell-b13920c70ed20823",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Ans:\n",
    "After introducing regularization term, there is no change on $\\Phi$. However,the distribution of $\\bw$ is more smooth\n",
    "e.g. when $\\lambda = 0.1$, we have\n",
    "\n",
    "$t = 0.35*x^2 + 2.45, |w_1 - w_2| = 2.1 $\n",
    "\n",
    "$t = 0.3*x^2 + 2.5, |w_1 - w_2| = 2.2 $\n",
    "\n",
    "Moreover, , the bigger $\\lambda$, the smaller $\\bw$ will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5c92f9ff9dd282413a3952250b7808f2",
     "grade": false,
     "grade_id": "cell-638bbedf69267917",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.5 Model selection by cross-validation (15 points)\n",
    "Use cross-validation to find a good choice of $M$ and $\\lambda$, given a dataset of $N=10$ datapoints generated with `gen_sine(10)`. You should write a function that tries (loops over) a reasonable range of choices of $M$ and $\\lambda$, and returns the choice with the best cross-validation error. In this case you use $K=5$ folds.\n",
    "\n",
    "You can let $M \\in (0, 1, ..., 10)$, and let $\\lambda \\in (e^{-10}, e^{-9}, ..., e^{0})$.\n",
    "\n",
    "a) (5 points) First of all, write a method `pred_error(x_train, x_valid, t_train, t_valid, M, lamb)` that compares the prediction of your method `fit_polynomial_reg` for a given set of parameters $M$ and $\\lambda$ to `t_valid`. It should return the prediction error for a single fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2cfb7f4cc04e4af74f4655e772e33b09",
     "grade": false,
     "grade_id": "cell-d631a845dec603be",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def pred_error(x_train, x_valid, t_train, t_valid, M, reg):\n",
    "    # YOUR CODE HERE  \n",
    "    w_ml, Phi = fit_polynomial_reg(x_train,t_train,M,reg)\n",
    "    pred_value = designmatrix(x_valid, M) @ w_ml\n",
    "    pred_err = np.sum((t_valid - pred_value)**2)/len(t_valid)\n",
    "    return pred_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42af593fbc74b19e94e38035eecbcb8f",
     "grade": true,
     "grade_id": "cell-ba7261e2eae040fd",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "N = 10\n",
    "x = np.linspace(-1, 1, N)\n",
    "t = 0.3*np.square(x) + 2.5\n",
    "M = 2\n",
    "reg = 0.1\n",
    "pred_err = pred_error(x[:-2], x[-2:], t[:-2], t[-2:], M, reg)\n",
    "\n",
    "assert pred_err < 0.001, \"pred_err is too big\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0e6aab76a18a6ef5f13d92c330d3cd5c",
     "grade": false,
     "grade_id": "cell-4c1ef9acd1f93493",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "b) (10 points) Now write a method find_best_m_and_lamb(x, t) that finds the best values for $M$ and $\\lambda$. The method should return the best $M$ and $\\lambda$. To get you started, here is a method you can use to generate indices of cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d673ab5c8a9231852af04a728bf93253",
     "grade": false,
     "grade_id": "cell-9abfee773ee6f780",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def kfold_indices(N, k):\n",
    "    all_indices = np.arange(N,dtype=int)\n",
    "    np.random.shuffle(all_indices)\n",
    "    idx = [int(i) for i in np.floor(np.linspace(0,N,k+1))]\n",
    "    train_folds = []\n",
    "    valid_folds = []\n",
    "    for fold in range(k):\n",
    "        valid_indices = all_indices[idx[fold]:idx[fold+1]]\n",
    "        valid_folds.append(valid_indices)\n",
    "        train_folds.append(np.setdiff1d(all_indices, valid_indices))\n",
    "    return train_folds, valid_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "65930a94ed4b46300fcf5aef054662a0",
     "grade": false,
     "grade_id": "cell-0553f08188fbfcd6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_best_m_and_lamb(x, t):\n",
    "    # YOUR CODE HERE\n",
    "    train_folds, valid_folds = kfold_indices(N,k)\n",
    "    best_error= float(\"inf\")\n",
    "    M_best = None\n",
    "    lamb_best = None\n",
    "    for m in M:\n",
    "        for lamb in regs:\n",
    "            error_all_folds = []\n",
    "            # for single set og lamb, m, we calculate the mean pred error for k folds\n",
    "            for i in range(k):\n",
    "                train_fold_indices = train_folds[i]\n",
    "                valid_fold_indices = valid_folds[i]\n",
    "                x_train_fold = np.take(x,train_folds[i])\n",
    "                x_valid_fold = np.take(x,valid_folds[i])\n",
    "                t_train_fold = np.take(t,train_folds[i])\n",
    "                t_valid_fold = np.take(t,valid_folds[i])\n",
    "                error_single_fold = pred_error(x_train_fold, x_valid_fold, t_train_fold, t_valid_fold, m, lamb)\n",
    "                error_all_folds.append(error_single_fold)\n",
    "            \n",
    "            # now we have the cross-validation error for a set of m and lamb\n",
    "            cross_error = np.mean(error_all_folds)\n",
    "            \n",
    "            if cross_error < best_error:\n",
    "                best_error = cross_error\n",
    "                M_best = m\n",
    "                lamb_best=lamb \n",
    "    \n",
    "    return M_best, lamb_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "01a14ccab5e63d3e68aa7bc209fc96f9",
     "grade": true,
     "grade_id": "cell-523aa38e51c8913c",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### This is not an empty cell (You don't need to care about it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "M = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "regs = np.exp([-10,-9,-8,-7,-6,-5,-4,-3,-2,-1,0])\n",
    "x1, t1 = gen_sine(10)\n",
    "# find the best model\n",
    "M_best, lamb_best = find_best_m_and_lamb(x1, t1)\n",
    "M_best, lamb_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "deeea83a847700e394b4255c8a87b84e",
     "grade": false,
     "grade_id": "cell-bef728e3824c8408",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.6 Why grid search? (5 points)\n",
    "\n",
    "Grid search is an commonly-used technique to tune hyper-parameters in a model.\n",
    "Considering the case described in the previous step of this assignment, running a grid search over the possible parameter values (10 possible values for both $M$ and $\\lambda$), results in two nested loops exploring $10 \\times 10 = 100$ different configurations for the model. \n",
    "\n",
    "a) (3 points) Why do we want to optimize by changing the two hyperparameters at the same time, and not in a sequential way? We could initialise all parameters randomly, fix one parameter at a time and iterate over the other, resulting in only $10 + 10 = 20$ experiments!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "de61dba67bed18b05301143c8a05a6c0",
     "grade": true,
     "grade_id": "cell-6bc03518283a57c2",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "It is obvious that if we do in a sequential way, we are not considering all possible combinations of pamameters, thus could lead to missing the best solution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2214afd7a561b8d9aa209e79be97e557",
     "grade": false,
     "grade_id": "cell-bea7dd205dc0bb91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For more complex models, the number of combinations easily explodes with the number of parameters. For example, with 5 parameters we would run $10 \\times 10 \\times 10 \\times 10 \\times 10 = 100,000$ experiments.\n",
    "\n",
    "b) (2 points) Try to think or find in literature one alternative to grid search to tune hyper-parameters more efficiently. Explain very briefly (2-3 lines max) how this method avoids the combinatorial explosion we have see in grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "10466bc2141b57ba22c6697bbbfb4e34",
     "grade": true,
     "grade_id": "cell-9bca3266ec3a3b4f",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "There are multple attemps to solve this problem:\n",
    " - Random search. Random search does not exhaustively search for all combinations of hyper parameters, but it samples out according to prior knowledge to reduce the size of search space.\n",
    " - Early stopping. Early stopping basically means we stop searching after we have found good enough result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "818d2036edbff780a450e6e1f4123eff",
     "grade": false,
     "grade_id": "cell-13e48288f0ba37af",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.7 Plot best cross-validated fit (5 points)\n",
    "\n",
    "For some dataset with $N = 10$, plot the model with the optimal $M$ and $\\lambda$ according to the cross-validation error, using the method you just wrote. In addition, the plot should show the dataset itself and the function that we try to approximate. Let the plot make clear which $M$ and $\\lambda$ were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9600d75426aa084eff763220c868f3da",
     "grade": true,
     "grade_id": "cell-f59cac6f24ce02fc",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x, t = gen_sine(N)\n",
    "plt.plot(x, t, 'ro', label=\"samples\")\n",
    "w_reg, Phi_reg = fit_polynomial_reg(x,t,M_best, lamb_best)\n",
    "# print(\"weights (M={}):\".format(M[i]), w)\n",
    "\n",
    "\n",
    "pred_x = np.linspace(0, 2*np.pi, 100)\n",
    "plt.plot(pred_x, np.sin(pred_x), \"y\", label=\"sin(x)\")\n",
    "\n",
    "detailed_Phi = designmatrix(pred_x, M_best)\n",
    "pred_reg = detailed_Phi.dot(w_reg)\n",
    "plt.plot(pred_x, pred_reg, \"b\", label=\"best polynomial fit\")\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"M={}, lambda={}\".format(M_best, lamb_best))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ba08cfc59239d89d38121e2922388632",
     "grade": false,
     "grade_id": "cell-f471e0e0ddf7667a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Bayesian Linear (Polynomial) Regression\n",
    "\n",
    "### 2.1 Sine 2 (5 points)\n",
    "\n",
    "Write a function `gen_sine2(N)` that behaves identically to `gen_sine(N)` except that the generated values $x_i$ are not linearly spaced, but drawn from a uniform distribution between $0$ and $2 \\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "734894a81470d4d49711de0c90998d3e",
     "grade": false,
     "grade_id": "cell-36addc88e1b3fe1d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gen_sine2(n):\n",
    "    # YOUR CODE HERE\n",
    "    x = np.random.uniform(0, 2*np.pi, n)\n",
    "    u = np.sin(x)\n",
    "    t = np.random.normal(u, 0.25, n)  \n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7003ef4307addbc6046a90a60fa9a83c",
     "grade": true,
     "grade_id": "cell-57a847b66fb591af",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "np.random.seed(42)\n",
    "N = 10\n",
    "x, t = gen_sine2(N)\n",
    "\n",
    "assert x.shape == (N,), \"the shape of x is incorrect\"\n",
    "assert t.shape == (N,), \"the shape of t is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e412c3e7676415a100329fdc5b083963",
     "grade": false,
     "grade_id": "cell-61f32a9b299aa500",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Compute Posterior (15 points)\n",
    "\n",
    "You're going to implement a Bayesian linear regression model, and fit it to the periodic data. Your regression model has a zero-mean isotropic Gaussian prior over the parameters, governed by a single (scalar) precision parameter $\\alpha$, i.e.:\n",
    "\n",
    "$$p(\\bw \\;|\\; \\alpha) = \\mathcal{N}(\\bw \\;|\\; 0, \\alpha^{-1} \\bI)$$\n",
    "\n",
    "The covariance and mean of the posterior are given by:\n",
    "\n",
    "$$\\bS_N= \\left( \\alpha \\bI + \\beta \\bPhi^T \\bPhi \\right)^{-1} $$\n",
    "$$\\bm_N = \\beta\\; \\bS_N \\bPhi^T \\bt$$\n",
    "\n",
    "where $\\alpha$ is the precision of the predictive distribution, and $\\beta$ is the noise precision. \n",
    "See MLPR chapter 3.3 for background.\n",
    "\n",
    "Write a method `fit_polynomial_bayes(x, t, M, alpha, beta)` that returns the mean $\\bm_N$ and covariance $\\bS_N$ of the posterior for a $M$-th order polynomial. In addition it should return the design matrix $\\bPhi$. The arguments `x`, `t` and `M` have the same meaning as in question 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a945f997e9dec6b173c23a922ef773b3",
     "grade": false,
     "grade_id": "cell-24d68ce462db8f40",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_polynomial_bayes(x, t, M, alpha, beta):\n",
    "    # YOUR CODE HERE\n",
    "    Phi = designmatrix(x, M)\n",
    "    S = np.linalg.inv(alpha * np.identity(M+1) + beta * Phi.T @ Phi)\n",
    "    m = beta * S @ Phi.T @ t\n",
    "    return m, S, Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "57b6869c4ee7ece5b4ecc93c5d8b3d0b",
     "grade": true,
     "grade_id": "cell-5cf266fca46cd4e9",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "N = 10\n",
    "x = np.linspace(-1, 1, N)\n",
    "t = 0.3*np.square(x) + 2.5\n",
    "M = 2\n",
    "alpha = 0.6\n",
    "beta = 16\n",
    "m, S, Phi = fit_polynomial_bayes(x, t, M, alpha, beta)\n",
    "\n",
    "assert m.shape == (M+1,), \"the shape of m is incorrect\" \n",
    "assert S.shape == (M+1, M+1), \"the shape of S is incorrect\"\n",
    "assert Phi.shape == (N, M+1), \"the shape of Phi is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a598daf8d35262215ce9deda7cc4bb7b",
     "grade": false,
     "grade_id": "cell-471f21c230ca4203",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.3 Prediction (10 points)\n",
    "\n",
    "The predictive distribution of Bayesian linear regression is:\n",
    "\n",
    "$$ p(t \\;|\\; \\bx, \\bt, \\alpha, \\beta) = \\mathcal{N}(t \\;|\\; \\bm_N^T \\phi(\\bx), \\sigma_N^2(\\bx))$$\n",
    "\n",
    "$$ \\sigma_N^2 = \\frac{1}{\\beta} + \\phi(\\bx)^T \\bS_N \\phi(\\bx) $$\n",
    "\n",
    "where $\\phi(\\bx)$ are the computed features for a new datapoint $\\bx$, and $t$ is the predicted variable for datapoint $\\bx$. \n",
    "\n",
    "Write a function that `predict_polynomial_bayes(x, m, S, beta)` that returns the predictive mean, variance and design matrix $\\bPhi$ given a new datapoint `x`, posterior mean `m`, posterior variance `S` and a choice of model variance `beta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "45fb4bc1bc26e2e2865d96eee138c9db",
     "grade": false,
     "grade_id": "cell-865ac2a455500d4b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_polynomial_bayes(x, m, S, beta):\n",
    "    # YOUR CODE HERE\n",
    "    sigma = np.array([])\n",
    "    Phi = designmatrix(x,m.shape[0]-1)\n",
    "    mean = m @ Phi.T\n",
    "    for i in range(len(Phi)):\n",
    "        Phi_i = Phi[i]     \n",
    "        sigma_i = (1/beta + Phi_i @ S @ Phi_i.T).reshape(())\n",
    "        sigma = np.append(sigma,sigma_i)\n",
    "    return mean, sigma, Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f36b9ca870925b0fc5229e429a95ca0",
     "grade": true,
     "grade_id": "cell-ecb92bcbe0131eb9",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test your function\n",
    "np.random.seed(42)\n",
    "N = 10\n",
    "x = np.linspace(-1, 1, N)\n",
    "m = np.random.rand(3)\n",
    "S = np.random.rand(3, 3)\n",
    "beta = 16\n",
    "mean, sigma, Phi = predict_polynomial_bayes(x, m, S, beta)\n",
    "\n",
    "assert mean.shape == (N,), \"the shape of mean is incorrect\"\n",
    "assert sigma.shape == (N,), \"the shape of sigma is incorrect\"\n",
    "assert Phi.shape == (N, m.shape[0]), \"the shape of Phi is incorrect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42768579435c85aa3198f6053e2c5e4b",
     "grade": false,
     "grade_id": "cell-50452fe12b83c7ce",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Plot predictive distribution (10 points)\n",
    "\n",
    "a) (5 points) Generate 10 datapoints with `gen_sine2(10)`. Compute the posterior mean and covariance for a Bayesian polynomial regression model with $M=4$, $\\alpha=\\frac{2}{5}$ and $\\beta=\\frac{1}{0.25^2}$.\n",
    "Plot the Bayesian predictive distribution, where you plot (for $x$ between 0 and $2 \\pi$) $t$'s predictive mean and the predictive standard deviation using `plt.fill_between(..., alpha=0.1)` (the alpha argument induces transparency).\n",
    "\n",
    "Include the datapoints in your plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4afe3760f68ff7c6b06f18b8e60c71a6",
     "grade": true,
     "grade_id": "cell-81339ee6f9873831",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "x,t = gen_sine2(10)\n",
    "xs = np.linspace(0, 2*np.pi, 256)\n",
    "m, s, _ = fit_polynomial_bayes(x, t, 4, 2/5, 1/(0.25**2))\n",
    "mean, sigma, Phi = predict_polynomial_bayes(xs, m, s, 1/(0.25**2))\n",
    "plt.plot(x, t, 'o')\n",
    "sin, = plt.plot(xs, np.sin(xs), label=\"sin\")\n",
    "pred, = plt.plot(xs, mean, label=\"predicted\")\n",
    "y1 = mean - np.sqrt(sigma)\n",
    "y2 = mean + np.sqrt(sigma)\n",
    "\n",
    "plt.fill_between(xs, y1, y2, alpha=0.1)\n",
    "plt.legend(handles=[sin, pred])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7ce5a14136b89a9d932d032d0cea9c0f",
     "grade": false,
     "grade_id": "cell-c556b2f5fcee8dee",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "b) (5 points) For a second plot, draw 100 samples from the parameters' posterior distribution. Each of these samples is a certain choice of parameters for 4-th order polynomial regression. \n",
    "Display each of these 100 polynomials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a6cbc9e5b0de9f7f9c847b1209275748",
     "grade": true,
     "grade_id": "cell-68cf4e7a773b42b9",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "M = 4\n",
    "alpha = 2.0 / 5\n",
    "beta = 1 / 0.25 ** 2\n",
    "\n",
    "x, t = gen_sine2(N)\n",
    "m, S, _ = fit_polynomial_bayes(x, t, M, alpha, beta)\n",
    "\n",
    "x_detailed = np.linspace(0, 2 * np.pi, 100)\n",
    "Phi_detailed = designmatrix(x_detailed, M)\n",
    "\n",
    "plt.scatter(x, t, facecolors='none', edgecolors='r', label='samples')\n",
    "plt.plot(x_detailed, np.sin(x_detailed), color='green', linewidth=3, label=r'$f(x)=\\sin(x)$')\n",
    "\n",
    "COUNT_BAYES = 100\n",
    "for i in np.arange(COUNT_BAYES):\n",
    "    # we draw a random w from its distribution defined by mean M of shape (M+1), and S of shape (M+1)x(M+1)\n",
    "    w = np.random.multivariate_normal(m, S)\n",
    "    plt.plot(x_detailed, Phi_detailed.dot(w), linewidth=1, alpha=0.2)\n",
    "\n",
    "plt.ylim([-1 * 2, 1 * 2])   \n",
    "plt.xlabel('x')\n",
    "plt.ylabel('t')\n",
    "plt.title('{} samples of Bayesian polynomial regression'.format(COUNT_BAYES))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a17d4c2e94d28da195bdeacca04814e4",
     "grade": false,
     "grade_id": "cell-4fdd4eca06d7b5d5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Additional questions (10 points)\n",
    "\n",
    "a) (5 points) Why is $\\beta=16$ the best choice of $\\beta$ in section 2.4?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "16413525920dbbe3f4bfe717867204ba",
     "grade": true,
     "grade_id": "cell-ac9287d87d554547",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "$\\beta=16 = \\frac{1}{0.25^{2}} \\longrightarrow \\sigma=0.25$\n",
    "\n",
    "This is the same as the standard deviation used in $gen\\_sine2$. Therefore, $\\beta=16$ makes the predictive distribution $p(\\mathbf{t}|\\mathbf{X}, \\mathbf{w}, \\beta) = \\mathcal{N}(\\mathbf{t}|\\mathbf{\\Phi w}, \\beta^{-1} \\mathbf{I})$ shares the same variance with the training data(samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5db5f599fe17da142e4a8d0632b2a42d",
     "grade": false,
     "grade_id": "cell-c3c65e3353057680",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "b) (5 points) What problems do we face when it comes to choosing basis functions in linear models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d28f3ba5fe296d03caca39c240fbb769",
     "grade": true,
     "grade_id": "cell-a3e38ba4c988b6a9",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "When it comes to choosing basis functions, there are multiple factors to consider:\n",
    "\n",
    " - Basis function types. In the example of polynomial regression, we can use $\\Phi_j(x) = x^j$. There are also alternative basis functions, such as gaussian functions, sigmoidal functions, or Fourier basis. There is no gold standard for choosing the right basis functions. In practice, prior knowledge should be utilized to choose the best basis functions.\n",
    " - Model complexity. In the exmaple of polynomial basis function, we have seen that when the model complexity is high (larger order of M), overfitting could happen, which leads to bad generazition; when the model complexity is low (smaller order of M), underfitting could happen.\n",
    " - Computational expenses. One should also consider how computational intensive the model is. For example, if samples in trainings data are already very high dimensional, one should carefully choose the model complexity to be not so high, thus balancing out the already high dimensional input data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
